{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/resources/common/.virtualenv/python2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1 = pd.read_csv('transaction_features1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ttrain = pd.read_csv('tj_05_training.csv', header=None)\n",
    "ttest = pd.read_csv('tj_05_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ttrain.columns = ['card_no', 'gender']\n",
    "ttest.columns = ['card_no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7934801971d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_txn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_txn_lg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_txn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf1' is not defined"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "tf1 = tf1.fillna(0)\n",
    "\n",
    "scaler = MinMaxScaler().fit(all_txn)\n",
    "tf1['avg_txn_lg'] = transformer.transform(tf1['avg_txn'].reshape(-1, 1))\n",
    "tf1['max_txn_lg'] = transformer.transform(tf1['max_txn'].reshape(-1, 1))\n",
    "tf1['min_txn_lg'] = transformer.transform(tf1['min_txn'].reshape(-1, 1))\n",
    "\n",
    "tf1['avg_txn_lgscale'] = scaler.transform(tf1['avg_txn_lg'].reshape(-1, 1))\n",
    "tf1['max_txn_lgscale'] = scaler.transform(tf1['max_txn_lg'].reshape(-1, 1))\n",
    "tf1['min_txn_lgscale'] = scaler.transform(tf1['min_txn_lg'].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ttrain_full = pd.merge(ttrain, tf1, on=\"card_no\")\n",
    "ttest_full = pd.merge(ttest, tf1, on=\"card_no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_no</th>\n",
       "      <th>gender</th>\n",
       "      <th>avg_txn</th>\n",
       "      <th>max_txn</th>\n",
       "      <th>min_txn</th>\n",
       "      <th>no_tran</th>\n",
       "      <th>pay_when_work</th>\n",
       "      <th>has_mer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1234000000000792</td>\n",
       "      <td>1</td>\n",
       "      <td>1907.6531</td>\n",
       "      <td>25000</td>\n",
       "      <td>50</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1234000000004032</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1234000000007128</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1234000000024393</td>\n",
       "      <td>1</td>\n",
       "      <td>1111.1111</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1234000000027939</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            card_no  gender    avg_txn  max_txn  min_txn  no_tran  \\\n",
       "0  1234000000000792       1  1907.6531    25000       50       98   \n",
       "1  1234000000004032       1    50.0000       50       50        1   \n",
       "2  1234000000007128       0    50.0000       50       50        1   \n",
       "3  1234000000024393       1  1111.1111     1500     1000        9   \n",
       "4  1234000000027939       0    50.0000       50       50        1   \n",
       "\n",
       "   pay_when_work  has_mer_id  \n",
       "0              1           1  \n",
       "1              0           1  \n",
       "2              0           1  \n",
       "3              1           1  \n",
       "4              0           1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttrain_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3 + Categorical + Remove duplicated predictors\n",
    "tf2 = pd.read_csv('feature3.csv')\n",
    "buy_men = pd.read_csv('buy_men.csv')\n",
    "buy_women = pd.read_csv('buy_women.csv')\n",
    "buy_cosmetic = pd.read_csv('buy_cosmetic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_no</th>\n",
       "      <th>avg_txn</th>\n",
       "      <th>max_txn</th>\n",
       "      <th>min_txn</th>\n",
       "      <th>max_cat_code</th>\n",
       "      <th>no_tran</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1234000000000001</td>\n",
       "      <td>2514.4231</td>\n",
       "      <td>100000</td>\n",
       "      <td>200</td>\n",
       "      <td>8062.0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1234000000000002</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1234000000000003</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1234000000000004</td>\n",
       "      <td>851.9231</td>\n",
       "      <td>4900</td>\n",
       "      <td>50</td>\n",
       "      <td>8999.0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1234000000000005</td>\n",
       "      <td>178.5714</td>\n",
       "      <td>250</td>\n",
       "      <td>100</td>\n",
       "      <td>5411.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            card_no    avg_txn  max_txn  min_txn  max_cat_code  no_tran\n",
       "0  1234000000000001  2514.4231   100000      200        8062.0       52\n",
       "1  1234000000000002    50.0000       50       50           NaN        1\n",
       "2  1234000000000003    50.0000       50       50           NaN        1\n",
       "3  1234000000000004   851.9231     4900       50        8999.0       52\n",
       "4  1234000000000005   178.5714      250      100        5411.0        7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Log Transformation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "transformer = FunctionTransformer(np.log1p)\n",
    "\n",
    "tf2['avg_txn_lg'] = transformer.transform(tf2['avg_txn'].reshape(-1, 1))\n",
    "tf2['max_txn_lg'] = transformer.transform(tf2['max_txn'].reshape(-1, 1))\n",
    "tf2['min_txn_lg'] = transformer.transform(tf2['min_txn'].reshape(-1, 1))\n",
    "\n",
    "# Fill NA\n",
    "tf2 = tf2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Number\n",
    "all_txn = tf2['avg_txn'].append(tf2['max_txn']).append(tf2['min_txn']).reshape(-1,1)\n",
    "all_txn = transformer.transform(all_txn)\n",
    "\n",
    "scaler = MinMaxScaler().fit(all_txn)\n",
    "tf2['avg_txn_lgscale'] = scaler.transform(tf2['avg_txn_lg'].reshape(-1, 1))\n",
    "tf2['max_txn_lgscale'] = scaler.transform(tf2['max_txn_lg'].reshape(-1, 1))\n",
    "tf2['min_txn_lgscale'] = scaler.transform(tf2['min_txn_lg'].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Label Encode\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder().fit(tf2['max_cat_code'])\n",
    "tf2['max_cat_encode'] = le.transform(tf2['max_cat_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Categorical Vsriables\n",
    "tf2_m = pd.merge(tf2, buy_men, on=\"card_no\", how=\"left\")\n",
    "tf2_mw = pd.merge(tf2_m, buy_women, on=\"card_no\", how=\"left\")\n",
    "tf2_mwc = pd.merge(tf2_mw, buy_cosmetic, on=\"card_no\", how=\"left\")\n",
    "\n",
    "# Fill NA\n",
    "tf2_mwc = tf2_mwc.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_no</th>\n",
       "      <th>avg_txn</th>\n",
       "      <th>max_txn</th>\n",
       "      <th>min_txn</th>\n",
       "      <th>max_cat_code</th>\n",
       "      <th>no_tran</th>\n",
       "      <th>avg_txn_lg</th>\n",
       "      <th>max_txn_lg</th>\n",
       "      <th>min_txn_lg</th>\n",
       "      <th>avg_txn_lgscale</th>\n",
       "      <th>max_txn_lgscale</th>\n",
       "      <th>min_txn_lgscale</th>\n",
       "      <th>max_cat_encode</th>\n",
       "      <th>buy_men</th>\n",
       "      <th>buy_women</th>\n",
       "      <th>buy_cosmetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1234000000000001</td>\n",
       "      <td>2514.4231</td>\n",
       "      <td>100000</td>\n",
       "      <td>200</td>\n",
       "      <td>8062.0</td>\n",
       "      <td>52</td>\n",
       "      <td>7.830196</td>\n",
       "      <td>11.512935</td>\n",
       "      <td>5.303305</td>\n",
       "      <td>0.303643</td>\n",
       "      <td>0.590491</td>\n",
       "      <td>0.106824</td>\n",
       "      <td>135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1234000000000002</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1234000000000003</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1234000000000004</td>\n",
       "      <td>851.9231</td>\n",
       "      <td>4900</td>\n",
       "      <td>50</td>\n",
       "      <td>8999.0</td>\n",
       "      <td>52</td>\n",
       "      <td>6.748669</td>\n",
       "      <td>8.497195</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>0.219403</td>\n",
       "      <td>0.355596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1234000000000005</td>\n",
       "      <td>178.5714</td>\n",
       "      <td>250</td>\n",
       "      <td>100</td>\n",
       "      <td>5411.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5.190573</td>\n",
       "      <td>5.525453</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>0.098044</td>\n",
       "      <td>0.124127</td>\n",
       "      <td>0.053222</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            card_no    avg_txn  max_txn  min_txn  max_cat_code  no_tran  \\\n",
       "0  1234000000000001  2514.4231   100000      200        8062.0       52   \n",
       "1  1234000000000002    50.0000       50       50           0.0        1   \n",
       "2  1234000000000003    50.0000       50       50           0.0        1   \n",
       "3  1234000000000004   851.9231     4900       50        8999.0       52   \n",
       "4  1234000000000005   178.5714      250      100        5411.0        7   \n",
       "\n",
       "   avg_txn_lg  max_txn_lg  min_txn_lg  avg_txn_lgscale  max_txn_lgscale  \\\n",
       "0    7.830196   11.512935    5.303305         0.303643         0.590491   \n",
       "1    3.931826    3.931826    3.931826         0.000000         0.000000   \n",
       "2    3.931826    3.931826    3.931826         0.000000         0.000000   \n",
       "3    6.748669    8.497195    3.931826         0.219403         0.355596   \n",
       "4    5.190573    5.525453    4.615121         0.098044         0.124127   \n",
       "\n",
       "   min_txn_lgscale  max_cat_encode  buy_men  buy_women  buy_cosmetic  \n",
       "0         0.106824             135      0.0        0.0           0.0  \n",
       "1         0.000000               0      0.0        0.0           0.0  \n",
       "2         0.000000               0      0.0        0.0           0.0  \n",
       "3         0.000000             152      0.0        1.0           0.0  \n",
       "4         0.053222              19      0.0        0.0           0.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf2_mwc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf2_mwc['buy_men'] = tf2_mwc['buy_men'].astype(int)\n",
    "tf2_mwc['buy_women'] = tf2_mwc['buy_women'].astype(int)\n",
    "tf2_mwc['buy_cosmetic'] = tf2_mwc['buy_cosmetic'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_no</th>\n",
       "      <th>gender</th>\n",
       "      <th>avg_txn</th>\n",
       "      <th>max_txn</th>\n",
       "      <th>min_txn</th>\n",
       "      <th>max_cat_code</th>\n",
       "      <th>no_tran</th>\n",
       "      <th>avg_txn_lg</th>\n",
       "      <th>max_txn_lg</th>\n",
       "      <th>min_txn_lg</th>\n",
       "      <th>avg_txn_lgscale</th>\n",
       "      <th>max_txn_lgscale</th>\n",
       "      <th>min_txn_lgscale</th>\n",
       "      <th>max_cat_encode</th>\n",
       "      <th>buy_men</th>\n",
       "      <th>buy_women</th>\n",
       "      <th>buy_cosmetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1234000000000792</td>\n",
       "      <td>1</td>\n",
       "      <td>1907.6531</td>\n",
       "      <td>25000</td>\n",
       "      <td>50</td>\n",
       "      <td>8062.0</td>\n",
       "      <td>98</td>\n",
       "      <td>7.554153</td>\n",
       "      <td>10.126671</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>0.282142</td>\n",
       "      <td>0.482515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1234000000004032</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1234000000007128</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1234000000024393</td>\n",
       "      <td>1</td>\n",
       "      <td>1111.1111</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>6011.0</td>\n",
       "      <td>9</td>\n",
       "      <td>7.014015</td>\n",
       "      <td>7.313887</td>\n",
       "      <td>6.908755</td>\n",
       "      <td>0.240071</td>\n",
       "      <td>0.263428</td>\n",
       "      <td>0.231872</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1234000000027939</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            card_no  gender    avg_txn  max_txn  min_txn  max_cat_code  \\\n",
       "0  1234000000000792       1  1907.6531    25000       50        8062.0   \n",
       "1  1234000000004032       1    50.0000       50       50           0.0   \n",
       "2  1234000000007128       0    50.0000       50       50           0.0   \n",
       "3  1234000000024393       1  1111.1111     1500     1000        6011.0   \n",
       "4  1234000000027939       0    50.0000       50       50           0.0   \n",
       "\n",
       "   no_tran  avg_txn_lg  max_txn_lg  min_txn_lg  avg_txn_lgscale  \\\n",
       "0       98    7.554153   10.126671    3.931826         0.282142   \n",
       "1        1    3.931826    3.931826    3.931826         0.000000   \n",
       "2        1    3.931826    3.931826    3.931826         0.000000   \n",
       "3        9    7.014015    7.313887    6.908755         0.240071   \n",
       "4        1    3.931826    3.931826    3.931826         0.000000   \n",
       "\n",
       "   max_txn_lgscale  min_txn_lgscale  max_cat_encode  buy_men  buy_women  \\\n",
       "0         0.482515         0.000000             135        0          0   \n",
       "1         0.000000         0.000000               0        0          0   \n",
       "2         0.000000         0.000000               0        0          0   \n",
       "3         0.263428         0.231872              78        0          0   \n",
       "4         0.000000         0.000000               0        0          0   \n",
       "\n",
       "   buy_cosmetic  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge Card_no\n",
    "ttrain_full = pd.merge(ttrain, tf2_mwc, on=\"card_no\")\n",
    "ttest_full = pd.merge(ttest, tf2_mwc, on=\"card_no\")\n",
    "ttrain_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "use_columns = [\n",
    "                'avg_txn_lg',\n",
    "                'max_txn_lg',\n",
    "                'min_txn_lg',\n",
    "                'buy_men',\n",
    "                'buy_women',\n",
    "                'buy_cosmetic',\n",
    "]\n",
    "\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# model = GaussianNB()\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# model = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier(n_estimators=50, learning_rate=1)\n",
    "\n",
    "# from sklearn import svm\n",
    "# model = svm.SVC()\n",
    "\n",
    "# model = XGBClassifier(max_depth=5)\n",
    "\n",
    "testsze = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56401644027738096"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Model\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    ttrain_full[use_columns],\n",
    "    ttrain_full['gender'], test_size = testsze)\n",
    "\n",
    "estimator = model.fit(x_train, y_train)\n",
    "\n",
    "np.mean(cross_val_score(estimator, x_test, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.grid_search import GridSearchCV\n",
    "# parameters = {'learning_rate':[0.05,0.1,0.2,0.3,0.5,0.7,1], 'n_estimators':[30,50,70,100,200]}\n",
    "# model = AdaBoostClassifier()\n",
    "# clf = GridSearchCV(model, parameters)\n",
    "# clf.fit(x_train, y_train)\n",
    "# print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save File\n",
    "predict_y = estimator.predict(ttest_full[use_columns])\n",
    "np.savetxt('5.txt', predict_y, fmt=\"%d\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
